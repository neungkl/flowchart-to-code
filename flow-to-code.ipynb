{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "SAMPLE_SIZE = 5\n",
    "SPLIT_RATIO = 0.9\n",
    "\n",
    "PADDING_SIZE = 5\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.arange(SAMPLE_SIZE) + 1\n",
    "np.random.seed(1234)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "split = (int) (SAMPLE_SIZE * SPLIT_RATIO)\n",
    "x_train_idx = index[0:split]\n",
    "x_test_idx = index[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_WORD = ['', 'statement', 'if', 'else', 'elseif', 'for', 'while', 'end', '<END>']\n",
    "N_ONEHOT_WORD = len(ALL_WORD) - 1\n",
    "CHARS_MAP = {v: k for k, v in enumerate(ALL_WORD)}\n",
    "IDX_MAP = dict(list(enumerate(ALL_WORD)))\n",
    "\n",
    "def to_onehot(word):\n",
    "    n_onehot = N_ONEHOT_WORD\n",
    "    idx = CHARS_MAP[word]\n",
    "    if idx == 0:\n",
    "        return np.zeros(n_onehot)\n",
    "    else:\n",
    "        onehot_vec = np.zeros(n_onehot)\n",
    "        onehot_vec[idx - 1] = 1\n",
    "        return onehot_vec\n",
    "\n",
    "def convert_to_feature_list(feature_words):\n",
    "    onehots = []\n",
    "    for word in feature_words:\n",
    "        onehots.append(to_onehot(word))\n",
    "    return np.array(onehots)\n",
    "        \n",
    "\n",
    "def convert_to_input_set(tokens, k):\n",
    "    n_tokens = len(tokens)\n",
    "    padded_token = [''] * k + tokens + ['<END>']\n",
    "    res = []\n",
    "    for i in range(n_tokens - 1):\n",
    "        res.append((\n",
    "            convert_to_feature_list(padded_token[i:i + k]),\n",
    "            to_onehot(padded_token[i + k])\n",
    "        ))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_generator(indexs):\n",
    "    files = glob.glob(\"./data/*\")\n",
    "    \n",
    "    while(True):\n",
    "        x_word = []\n",
    "        x_image = []\n",
    "        y = []\n",
    "        \n",
    "        for idx in indexs:\n",
    "            picture_files = list(filter(re.compile(\".\\/data\\/sample-\" + str(idx) + \"-\\d+.jpg\").search, files))\n",
    "            lang_file = list(filter(re.compile(\".\\/data\\/sample-\" + str(idx) + \"-lang.txt\").search, files))\n",
    "            \n",
    "            if len(lang_file) == 0:\n",
    "                continue\n",
    "            \n",
    "            with open(lang_file[0], 'r') as file:\n",
    "                lang = [l.strip().split(\" \")[0] for l in file.read().split(\"\\n\") if len(l)]\n",
    "                lang = list(map(lambda x: \"statement\" if x.startswith(\"statement\") else x, lang))\n",
    "            \n",
    "            embed_lang = convert_to_input_set(lang, PADDING_SIZE)\n",
    "            \n",
    "            for picture in picture_files:\n",
    "                image = Image.open(picture).convert('L')\n",
    "                image = image.convert()\n",
    "                image = image.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "                image = np.asarray(image).reshape((IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "                image = image / 255\n",
    "\n",
    "                for lang in embed_lang:\n",
    "                    x_word.append(lang[0])\n",
    "                    x_image.append(image)\n",
    "                    y.append(lang[1])\n",
    "                    \n",
    "                    if len(y) >= BATCH_SIZE:\n",
    "                        yield [np.array(x_word), np.array(x_image)], np.array(y)\n",
    "                        x_word = []\n",
    "                        x_image = []\n",
    "                        y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_24 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 256, 256, 64) 3200        input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling2D) (None, 128, 128, 64) 0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 128, 128, 128 204928      max_pooling2d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 128, 128, 128 409728      conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling2D) (None, 64, 64, 128)  0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 64, 64, 128)  0           max_pooling2d_66[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 64, 64, 256)  819456      dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 64, 64, 256)  1638656     conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 64, 64, 256)  1638656     conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling2D) (None, 32, 32, 256)  0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 32, 32, 256)  0           max_pooling2d_67[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 32, 32, 256)  590080      dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling2D) (None, 16, 16, 256)  0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 16, 16, 256)  0           max_pooling2d_68[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 16, 512)  1180160     dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           (None, 5, 7)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling2D) (None, 8, 8, 512)    0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_25 (LSTM)                  (None, 5, 32)        5120        input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 8, 8, 512)    0           max_pooling2d_69[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm_26 (LSTM)                  (None, 5, 32)        8320        lstm_25[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 32768)        0           dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_27 (LSTM)                  (None, 32)           8320        lstm_26[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 2048)         67110912    flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 2080)         0           lstm_27[0][0]                    \n",
      "                                                                 dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 1024)         2130944     concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1024)         0           dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 1024)         1049600     dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 1024)         0           dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 1024)         1049600     dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 1024)         0           dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 7)            7175        dropout_39[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 83,754,631\n",
      "Trainable params: 83,754,631\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Concatenate, Conv2D, MaxPooling2D, Dropout, LSTM, RepeatVector\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model\n",
    "\n",
    "def generate_model():\n",
    "    word_input = Input(shape=(PADDING_SIZE, N_ONEHOT_WORD))\n",
    "    image_input = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "    \n",
    "    img = Conv2D(32, (3, 3), padding='same', activation='relu')(image_input)\n",
    "    img = Conv2D(32, (3, 3), padding='same', activation='relu')(image_input)\n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(64, (3, 3), padding='same', activation='relu')(img)\n",
    "    img = Conv2D(64, (3, 3), padding='same', activation='relu')(img)\n",
    "    img = Conv2D(64, (3, 3), padding='same', activation='relu')(img)\n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Dropout(0.25)(img)\n",
    "    img = Conv2D(128, (3, 3), padding='same', activation='relu')(img)\n",
    "    img = Conv2D(128, (3, 3), padding='same', activation='relu')(img)\n",
    "    img = Conv2D(128, (3, 3), padding='same', activation='relu')(img)\n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Dropout(0.25)(img)\n",
    "    \n",
    "    img = Flatten()(img)\n",
    "    img = Dense(512, activation='relu')(img)\n",
    "    img = Dropout(0.3)(img)\n",
    "    img = Dense(512, activation='relu')(img)\n",
    "    img = Dropout(0.3)(img)\n",
    "    \n",
    "    img = RepeatVector(PADDING_SIZE)(img)\n",
    "    \n",
    "    w = LSTM(64, return_sequences=True, dropout=0.75)(word_input)\n",
    "    w = LSTM(64, return_sequences=True, dropout=0.75)(w)\n",
    "    \n",
    "    x = Concatenate()([w, img])\n",
    "    x = LSTM(256, return_sequences=True, dropout=0.75)(x)\n",
    "    x = LSTM(256, activation='relu')(x)\n",
    "    \n",
    "    outputs = Dense(N_ONEHOT_WORD, activation='softmax')(x)\n",
    "\n",
    "    optimizer = RMSprop(lr=0.0001, clipvalue=1.0)\n",
    "    model = Model(inputs=[word_input, image_input], outputs=outputs)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(generate_model().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_26 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 256, 256, 4)  40          input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling2D) (None, 128, 128, 4)  0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 128, 128, 8)  296         max_pooling2d_70[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling2D) (None, 64, 64, 8)    0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_72 (MaxPooling2D) (None, 32, 32, 8)    0           max_pooling2d_71[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 32, 32, 8)    0           max_pooling2d_72[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 32, 32, 16)   1168        dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_73 (MaxPooling2D) (None, 16, 16, 16)   0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling2D) (None, 8, 8, 16)     0           max_pooling2d_73[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling2D) (None, 4, 4, 16)     0           max_pooling2d_74[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_25 (InputLayer)           (None, 5, 7)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 4, 4, 16)     0           max_pooling2d_75[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm_28 (LSTM)                  (None, 5, 8)         512         input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 256)          0           dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_29 (LSTM)                  (None, 8)            544         lstm_28[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 16)           4112        flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 24)           0           lstm_29[0][0]                    \n",
      "                                                                 dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 8)            200         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 7)            63          dense_46[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,935\n",
      "Trainable params: 6,935\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Concatenate, Conv2D, MaxPooling2D, Dropout, LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "def generate_model_small():\n",
    "    word_input = Input(shape=(PADDING_SIZE, N_ONEHOT_WORD))\n",
    "    image_input = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "    \n",
    "    img = Conv2D(4, (3, 3), padding='same', activation='relu')(image_input)\n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(8, (3, 3), padding='same', activation='relu')(img)\n",
    "    img = MaxPooling2D()(img)\n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Dropout(0.1)(img)\n",
    "    img = Conv2D(16, (3, 3), padding='same', activation='relu')(img)\n",
    "    img = MaxPooling2D()(img)\n",
    "    img = MaxPooling2D()(img)\n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Dropout(0.1)(img)\n",
    "    img = Flatten()(img)\n",
    "    img = Dense(16, activation='relu')(img)\n",
    "    \n",
    "    w = LSTM(8, return_sequences=True)(word_input)\n",
    "    w = LSTM(8)(w)\n",
    "    \n",
    "    x = Concatenate()([w, img])\n",
    "    x = Dense(8, activation='relu')(x)\n",
    "    \n",
    "    outputs = Dense(N_ONEHOT_WORD, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[word_input, image_input], outputs=outputs)\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(generate_model_small().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "\n",
    "class TensorBoard(Callback):\n",
    "\n",
    "    def __init__(self, log_dir='./logs',\n",
    "                 write_graph=False,\n",
    "                 start_steps=0,\n",
    "                 batch_freq=1):\n",
    "        super(TensorBoard, self).__init__()\n",
    "        \n",
    "        global tf, projector\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.contrib.tensorboard.plugins import projector\n",
    "        \n",
    "        self.log_dir = log_dir\n",
    "        self.batch_freq = batch_freq\n",
    "        self.write_graph = write_graph\n",
    "        \n",
    "        self.start_steps = start_steps\n",
    "        self.steps_counter = 1\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        self.sess = K.get_session()\n",
    "        \n",
    "        self.merged = tf.summary.merge_all()\n",
    "\n",
    "        if self.write_graph:\n",
    "            self.writer = tf.summary.FileWriter(self.log_dir,\n",
    "                                                self.sess.graph)\n",
    "        else:\n",
    "            self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "            \n",
    "    def save_scalar(self, logs):\n",
    "        log = logs or {}\n",
    "        \n",
    "        for name, value in logs.items():\n",
    "            if name in ['batch', 'size']:\n",
    "                continue\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.writer.add_summary(\n",
    "                summary,\n",
    "                self.start_steps + self.steps_counter\n",
    "            )\n",
    "        self.writer.flush()\n",
    "            \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if self.steps_counter % self.batch_freq == 0:\n",
    "            self.save_scalar(logs)\n",
    "        self.steps_counter += 1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.save_scalar(logs)        \n",
    "\n",
    "    def on_train_end(self, _):\n",
    "        self.writer.close()\n",
    "\n",
    "class ModelCheckpoint(Callback):\n",
    "\n",
    "    def __init__(self,\n",
    "                 filepath,\n",
    "                 start_steps=0,\n",
    "                 batch_freq=1):\n",
    "        super(ModelCheckpoint, self).__init__()\n",
    "        \n",
    "        self.filepath = filepath\n",
    "        \n",
    "        self.steps_counter = 0\n",
    "        self.start_steps = start_steps\n",
    "        self.batch_freq = batch_freq\n",
    "        \n",
    "        self.steps_counter\n",
    "        \n",
    "    def save_model(self):\n",
    "        self.model.save_weights(self.filepath, overwrite=True)\n",
    "        \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if self.steps_counter % self.batch_freq == 0:\n",
    "            self.save_model()\n",
    "        self.steps_counter += 1\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 2/20 [==>...........................] - ETA: 42s - loss: 1.9592 - acc: 0.0938     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:116: UserWarning: Method on_batch_end() is slow compared to the batch update (0.783741). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 16s 775ms/step - loss: 1.5685 - acc: 0.5188 - val_loss: 1.5170 - val_acc: 0.6625\n",
      "Epoch 2/3\n",
      " 4/20 [=====>........................] - ETA: 6s - loss: 1.1598 - acc: 0.7344"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-9ebcb4359822>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         ModelCheckpoint(\n\u001b[1;32m     18\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./model/model-weight.hdf5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mbatch_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         )\n\u001b[1;32m     21\u001b[0m     ]\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2112\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2113\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2114\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1830\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1832\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = generate_model_small()\n",
    "# model.load_weights('./model/model-weight.hdf5')\n",
    "\n",
    "model.fit_generator(\n",
    "    input_generator(x_train_idx),\n",
    "    steps_per_epoch=20,\n",
    "    validation_data = input_generator(x_test_idx),\n",
    "    validation_steps = 10,\n",
    "    max_queue_size=5,\n",
    "    epochs=3,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=[\n",
    "        TensorBoard(\n",
    "            log_dir=\"./model/logs/\",\n",
    "            batch_freq=5\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=\"./model/model-weight.hdf5\",\n",
    "            batch_freq=10\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
