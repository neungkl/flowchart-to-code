{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "SAMPLE_SIZE = 5090\n",
    "SPLIT_RATIO = 0.7\n",
    "\n",
    "PADDING_SIZE = 5\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.arange(SAMPLE_SIZE) + 1\n",
    "np.random.seed(1234)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "split = (int) (SAMPLE_SIZE * SPLIT_RATIO)\n",
    "x_train_idx = index[0:split]\n",
    "x_test_idx = index[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_WORD = ['', 'statement', 'if', 'else', 'elseif', 'for', 'while', 'end', '<START>', '<END>']\n",
    "N_ONEHOT_WORD = len(ALL_WORD) - 1\n",
    "CHARS_MAP = {v: k for k, v in enumerate(ALL_WORD)}\n",
    "IDX_MAP = dict(list(enumerate(ALL_WORD)))\n",
    "\n",
    "def to_onehot(word):\n",
    "    n_onehot = N_ONEHOT_WORD\n",
    "    idx = CHARS_MAP[word]\n",
    "    if idx == 0:\n",
    "        return np.zeros(n_onehot)\n",
    "    else:\n",
    "        onehot_vec = np.zeros(n_onehot)\n",
    "        onehot_vec[idx - 1] = 1\n",
    "        return onehot_vec\n",
    "\n",
    "def convert_to_feature_list(feature_words):\n",
    "    onehots = []\n",
    "    for word in feature_words:\n",
    "        onehots.append(to_onehot(word))\n",
    "    return np.array(onehots)\n",
    "        \n",
    "\n",
    "def convert_to_input_set(tokens, k):\n",
    "    n_tokens = len(tokens)\n",
    "    padded_token = [''] * (k - 1) + [\"<START>\"] + tokens + [\"<END>\"]\n",
    "    res = []\n",
    "    for i in range(n_tokens + 1):\n",
    "        res.append((\n",
    "            convert_to_feature_list(padded_token[i:i + k]),\n",
    "            to_onehot(padded_token[i + k])\n",
    "        ))\n",
    "    return res\n",
    "\n",
    "def read_image(image_file):\n",
    "    image = Image.open(image_file).convert('L')\n",
    "    image = image.convert()\n",
    "    image = image.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "    image = np.asarray(image).reshape((IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "    return 1 - (image / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_generator(indexs):\n",
    "    files = glob.glob(\"./data/*\")\n",
    "    \n",
    "    while(True):\n",
    "        x_word = []\n",
    "        x_image = []\n",
    "        y = []\n",
    "        \n",
    "        for idx in indexs:\n",
    "            picture_files = list(filter(re.compile(\".\\/data\\/sample-\" + str(idx) + \"-\\d+.jpg\").search, files))\n",
    "            lang_file = list(filter(re.compile(\".\\/data\\/sample-\" + str(idx) + \"-lang.txt\").search, files))\n",
    "            \n",
    "            if len(lang_file) == 0:\n",
    "                continue\n",
    "            \n",
    "            with open(lang_file[0], 'r') as file:\n",
    "                lang = [l.strip().split(\" \")[0] for l in file.read().split(\"\\n\") if len(l)]\n",
    "                lang = list(map(lambda x: \"statement\" if x.startswith(\"statement\") else x, lang))\n",
    "            \n",
    "            embed_lang = convert_to_input_set(lang, PADDING_SIZE)\n",
    "            \n",
    "            for picture in picture_files:\n",
    "                image = read_image(picture)\n",
    "\n",
    "                for lang in embed_lang:\n",
    "                    x_word.append(lang[0])\n",
    "                    x_image.append(image)\n",
    "                    y.append(lang[1])\n",
    "                    \n",
    "                    if len(y) >= BATCH_SIZE:\n",
    "                        yield [np.array(x_word), np.array(x_image)], np.array(y)\n",
    "                        x_word = []\n",
    "                        x_image = []\n",
    "                        y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_input_generator():\n",
    "    count = 0\n",
    "    for x,y in input_generator(x_train_idx):\n",
    "        count += 1\n",
    "        if count > 10:\n",
    "            break\n",
    "\n",
    "# test_input_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Concatenate, Conv2D, MaxPooling2D, LSTM, RepeatVector, Embedding\n",
    "from keras.layers import Reshape, UpSampling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "def generate_model():\n",
    "    word_input = Input(batch_shape=(BATCH_SIZE, PADDING_SIZE, N_ONEHOT_WORD))\n",
    "    image_input = Input(batch_shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "    \n",
    "    img = Conv2D(32, (3, 3), padding='same', activation='relu', trainable=False)(image_input)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(64, (3,3), padding='same', activation='relu', trainable=False)(img)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(92, (3,3), padding='same', activation='relu', trainable=False)(img)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(128, (3,3), padding='same', activation='relu', trainable=False)(img)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(192, (3,3), padding='same', activation='relu', trainable=False)(img)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(224, (3,3), padding='same', activation='relu', trainable=False)(img)\n",
    "    \n",
    "    img = Flatten()(img)\n",
    "    img = Dense(2048, trainable=False)(img)\n",
    "    img = RepeatVector(PADDING_SIZE)(img)\n",
    "    \n",
    "    w = LSTM(512, return_sequences=True, stateful=True)(word_input)\n",
    "    w = LSTM(512, return_sequences=True, stateful=True)(w)\n",
    "    \n",
    "    x = Concatenate()([w, img])\n",
    "    x = LSTM(512, return_sequences=True, stateful=True)(x)\n",
    "    x = LSTM(512, stateful=True)(x)\n",
    "    \n",
    "    outputs = Dense(N_ONEHOT_WORD, activation='softmax')(x)\n",
    "\n",
    "    optimizer = Adam(lr=0.0001)\n",
    "    model = Model(inputs=[word_input, image_input], outputs=outputs)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_31 (InputLayer)           (4, 256, 256, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (4, 256, 256, 32)    320         input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling2D) (4, 128, 128, 32)    0           conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (4, 128, 128, 64)    18496       max_pooling2d_81[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling2D) (4, 64, 64, 64)      0           conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (4, 64, 64, 92)      53084       max_pooling2d_82[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling2D) (4, 32, 32, 92)      0           conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (4, 32, 32, 128)     106112      max_pooling2d_83[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_84 (MaxPooling2D) (4, 16, 16, 128)     0           conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (4, 16, 16, 192)     221376      max_pooling2d_84[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_85 (MaxPooling2D) (4, 8, 8, 192)       0           conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (4, 8, 8, 224)       387296      max_pooling2d_85[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           (4, 5, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (4, 14336)           0           conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_37 (LSTM)                  (4, 5, 512)          1069056     input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (4, 2048)            29362176    flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_38 (LSTM)                  (4, 5, 512)          2099200     lstm_37[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_12 (RepeatVector) (4, 5, 2048)         0           dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (4, 5, 2560)         0           lstm_38[0][0]                    \n",
      "                                                                 repeat_vector_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm_39 (LSTM)                  (4, 5, 512)          6293504     concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lstm_40 (LSTM)                  (4, 512)             2099200     lstm_39[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (4, 9)               4617        lstm_40[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 41,714,437\n",
      "Trainable params: 11,565,577\n",
      "Non-trainable params: 30,148,860\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(generate_model().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_img_v7():\n",
    "    image_input = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "    \n",
    "    img = Conv2D(32, (3, 3), padding='same', activation='relu')(image_input)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(64, (3,3), padding='same', activation='relu')(img)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(92, (3,3), padding='same', activation='relu')(img)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(128, (3,3), padding='same', activation='relu')(img)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(192, (3,3), padding='same', activation='relu')(img)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(224, (3,3), padding='same', activation='relu')(img)\n",
    "    \n",
    "    img = Flatten()(img)\n",
    "    img = Dense(2048)(img)\n",
    "    \n",
    "    img = Dense(8*8*224)(img)\n",
    "    img = Reshape((8,8,224))(img)\n",
    "    \n",
    "    img = Conv2D(224, (3,3), padding='same', activation='relu')(img)\n",
    "    img = UpSampling2D()(img)\n",
    "    \n",
    "    img = Conv2D(192, (3,3), padding='same', activation='relu')(img)\n",
    "    img = UpSampling2D()(img)\n",
    "    \n",
    "    img = Conv2D(128, (3,3), padding='same', activation='relu')(img)\n",
    "    img = UpSampling2D()(img)\n",
    "    \n",
    "    img = Conv2D(92, (3,3), padding='same', activation='relu')(img)\n",
    "    img = UpSampling2D()(img)\n",
    "    \n",
    "    img = Conv2D(64, (3,3), padding='same', activation='relu')(img)\n",
    "    img = UpSampling2D()(img)\n",
    "    \n",
    "    img = Conv2D(32, (3, 3), padding='same', activation='relu')(img)\n",
    "    img = Conv2D(1, (3, 3), padding='same', activation='sigmoid')(img)\n",
    "\n",
    "    outputs = img\n",
    "\n",
    "    model = Model(inputs=image_input, outputs=outputs)\n",
    "    model.compile(optimizer='adadelta',\n",
    "                  loss='binary_crossentropy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_152 : conv2d_139\n",
      "max_pooling2d_91 : max_pooling2d_86\n",
      "conv2d_153 : conv2d_140\n",
      "max_pooling2d_92 : max_pooling2d_87\n",
      "conv2d_154 : conv2d_141\n",
      "max_pooling2d_93 : max_pooling2d_88\n",
      "conv2d_155 : conv2d_142\n",
      "max_pooling2d_94 : max_pooling2d_89\n",
      "conv2d_156 : conv2d_143\n",
      "max_pooling2d_95 : max_pooling2d_90\n",
      "conv2d_157 : conv2d_144\n",
      "dense_36 : dense_34\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "\n",
    "def migrate_model():\n",
    "    global model\n",
    "    model_img = generate_model_img_v7()\n",
    "    model_img.load_weights('./model/model-ae-weight-7.hdf5')\n",
    "    model_img_weights = model_img.get_weights()\n",
    "\n",
    "    model = generate_model()\n",
    "\n",
    "\n",
    "    target_layer = list(range(1,12)) + [15]\n",
    "    origin_layer = list(range(1,12)) + [13]\n",
    "\n",
    "    for i, t in enumerate(target_layer):\n",
    "        o = origin_layer[i]\n",
    "        print(model.layers[t].name + \" : \" + model_img.layers[o].name)\n",
    "    #     if (t == 15):\n",
    "    #         w = model.layers[t].get_weights()\n",
    "    #         print(w[0].shape, w[1].shape)\n",
    "    #         w = model_img.layers[o].get_weights()\n",
    "    #         print(w[0].shape, w[1].shape)\n",
    "        model.layers[t].set_weights(\n",
    "            model_img.layers[o].get_weights()\n",
    "        )\n",
    "    \n",
    "    del model_img\n",
    "\n",
    "migrate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "class TensorBoard(Callback):\n",
    "\n",
    "    def __init__(self, log_dir='./logs',\n",
    "                 write_graph=False,\n",
    "                 start_steps=0,\n",
    "                 batch_freq=1):\n",
    "        super(TensorBoard, self).__init__()\n",
    "        \n",
    "        global tf, projector\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.contrib.tensorboard.plugins import projector\n",
    "        \n",
    "        self.log_dir = log_dir\n",
    "        self.batch_freq = batch_freq\n",
    "        self.write_graph = write_graph\n",
    "        \n",
    "        self.start_steps = start_steps\n",
    "        self.steps_counter = 1\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        self.sess = K.get_session()\n",
    "        \n",
    "        self.merged = tf.summary.merge_all()\n",
    "\n",
    "        if self.write_graph:\n",
    "            self.writer = tf.summary.FileWriter(self.log_dir,\n",
    "                                                self.sess.graph)\n",
    "        else:\n",
    "            self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "            \n",
    "    def save_scalar(self, logs):\n",
    "        log = logs or {}\n",
    "        \n",
    "        for name, value in logs.items():\n",
    "            if name in ['batch', 'size']:\n",
    "                continue\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.writer.add_summary(\n",
    "                summary,\n",
    "                self.start_steps + self.steps_counter\n",
    "            )\n",
    "        self.writer.flush()\n",
    "            \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if self.steps_counter % self.batch_freq == 0:\n",
    "            self.save_scalar(logs)\n",
    "        self.steps_counter += 1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.save_scalar(logs)        \n",
    "\n",
    "    def on_train_end(self, _):\n",
    "        self.writer.close()\n",
    "\n",
    "class ModelCheckpoint(Callback):\n",
    "\n",
    "    def __init__(self,\n",
    "                 filepath,\n",
    "                 start_steps=0,\n",
    "                 batch_freq=1):\n",
    "        super(ModelCheckpoint, self).__init__()\n",
    "        \n",
    "        self.filepath = filepath\n",
    "        \n",
    "        self.steps_counter = 0\n",
    "        self.start_steps = start_steps\n",
    "        self.batch_freq = batch_freq\n",
    "        \n",
    "        self.steps_counter\n",
    "        \n",
    "    def save_model(self):\n",
    "        self.model.save_weights(self.filepath, overwrite=True)\n",
    "        \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if self.steps_counter % self.batch_freq == 0:\n",
    "            self.save_model()\n",
    "        self.steps_counter += 1\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "    2/50094 [..............................] - ETA: 23:50:08 - loss: 2.1860 - acc: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:116: UserWarning: Method on_batch_end() is slow compared to the batch update (2.028638). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:116: UserWarning: Method on_batch_end() is slow compared to the batch update (1.014886). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34441/50094 [===================>..........] - ETA: 25:10 - loss: 0.6681 - acc: 0.7561"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45140/50094 [==========================>...] - ETA: 7:56 - loss: 0.5777 - acc: 0.7885"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50094/50094 [==============================] - 4940s 99ms/step - loss: 0.5464 - acc: 0.8000 - val_loss: 0.4662 - val_acc: 0.8285\n",
      "Epoch 2/3\n",
      "50094/50094 [==============================] - 4993s 100ms/step - loss: 0.2125 - acc: 0.9179 - val_loss: 0.2728 - val_acc: 0.8928\n",
      "Epoch 3/3\n",
      "50094/50094 [==============================] - 4965s 99ms/step - loss: 0.1528 - acc: 0.9364 - val_loss: 0.2460 - val_acc: 0.9021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5e594ba668>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    input_generator(x_train_idx),\n",
    "    steps_per_epoch=50094,\n",
    "    validation_data=input_generator(x_test_idx),\n",
    "    validation_steps=3382,\n",
    "    max_queue_size=5,\n",
    "    epochs=3,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=[\n",
    "        TensorBoard(\n",
    "            log_dir=\"./model/logs/\",\n",
    "            batch_freq=5\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=\"./model/model-weight-1.hdf5\",\n",
    "            batch_freq=100\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
