{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 5090\n",
    "SPLIT_RATIO = 0.7\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "steps_per_epoch = 3000\n",
    "validation_steps = 1082\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.arange(SAMPLE_SIZE) + 1\n",
    "np.random.seed(1234)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "split = (int) (SAMPLE_SIZE * SPLIT_RATIO)\n",
    "x_train_idx = index[0:split]\n",
    "x_test_idx = index[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_file):\n",
    "    image = Image.open(image_file).convert('L')\n",
    "    image = image.convert()\n",
    "    image = image.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "    image = np.asarray(image).reshape((IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "    return 1 - (image / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_generator(indexs):\n",
    "    files = glob.glob(\"./data/*\")\n",
    "    \n",
    "    while(True):\n",
    "        x_image = []\n",
    "        y_image = []\n",
    "        \n",
    "        for idx in indexs:\n",
    "            picture_files = list(filter(re.compile(\".\\/data\\/sample-\" + str(idx) + \"-\\d+.jpg\").search, files))\n",
    "            \n",
    "            for picture in picture_files:\n",
    "                image = read_image(picture)\n",
    "                picture = picture.split(\".\")\n",
    "                image_blank = read_image(\".\" + picture[1] + \"-blank.\" + picture[2])\n",
    "                \n",
    "                x_image.append(image)\n",
    "                y_image.append(image_blank)\n",
    "\n",
    "                if len(y_image) >= BATCH_SIZE:\n",
    "                    yield np.array(x_image), np.array(y_image)\n",
    "                    x_image = []\n",
    "                    y_image = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Reshape, Conv2DTranspose, UpSampling2D, BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_v1():\n",
    "    image_input = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "    \n",
    "    img = Conv2D(32, (3, 3), padding='same', activation='relu')(image_input)\n",
    "    img = Conv2D(32, (3, 3), padding='same', activation='relu')(img)\n",
    "    \n",
    "    img = Conv2DTranspose(32, (3, 3), padding='same', activation='relu')(img)\n",
    "    img = Conv2DTranspose(32, (3, 3), padding='same', activation='relu')(img)\n",
    "    img = Conv2DTranspose(1, (3, 3), padding='same', activation='sigmoid')(img)\n",
    "\n",
    "    outputs = img\n",
    "\n",
    "    optimizer = RMSprop()\n",
    "    model = Model(inputs=image_input, outputs=outputs)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_v2():\n",
    "    image_input = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "    \n",
    "    img = Conv2D(32, (3, 3), padding='same', activation='relu')(image_input)\n",
    "    img = Conv2D(32, (3, 3), padding='same', activation='relu')(img)\n",
    "    img = MaxPooling2D()(img)\n",
    "    \n",
    "    img = Conv2D(64, (3,3), padding='same', activation='relu')(img)\n",
    "    \n",
    "    img = Conv2DTranspose(64, (3,3), padding='same', activation='relu')(img)\n",
    "    img = UpSampling2D()(img)\n",
    "    \n",
    "    img = Conv2DTranspose(32, (3, 3), padding='same', activation='relu')(img)\n",
    "    img = Conv2DTranspose(32, (3, 3), padding='same', activation='relu')(img)\n",
    "    img = Conv2DTranspose(1, (3, 3), padding='same', activation='sigmoid')(img)\n",
    "\n",
    "    outputs = img\n",
    "\n",
    "    optimizer = RMSprop()\n",
    "    model = Model(inputs=image_input, outputs=outputs)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_v3():\n",
    "    image_input = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "    \n",
    "    img = Conv2D(32, (3, 3), padding='same', activation='relu', trainable=False)(image_input)\n",
    "    img = Conv2D(32, (3, 3), padding='same', activation='relu', trainable=False)(img)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(64, (3,3), padding='same', activation='relu', trainable=False)(img)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(92, (3,3), padding='same', activation='relu')(img)\n",
    "    \n",
    "    img = Conv2DTranspose(92, (3,3), padding='same', activation='relu')(img)\n",
    "    img = UpSampling2D()(img)\n",
    "    \n",
    "    img = Conv2DTranspose(64, (3,3), padding='same', activation='relu', trainable=False)(img)\n",
    "    img = UpSampling2D()(img)\n",
    "    \n",
    "    img = Conv2DTranspose(32, (3, 3), padding='same', activation='relu', trainable=False)(img)\n",
    "    img = Conv2DTranspose(32, (3, 3), padding='same', activation='relu', trainable=False)(img)\n",
    "    img = Conv2DTranspose(1, (3, 3), padding='same', activation='sigmoid', trainable=False)(img)\n",
    "\n",
    "    outputs = img\n",
    "\n",
    "    optimizer = RMSprop()\n",
    "    model = Model(inputs=image_input, outputs=outputs)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_v4():\n",
    "    image_input = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "    \n",
    "    img = Conv2D(32, (3, 3), padding='same', activation='relu', trainable=False)(image_input)\n",
    "    img = Conv2D(32, (3, 3), padding='same', activation='relu', trainable=False)(img)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(64, (3,3), padding='same', activation='relu', trainable=False)(img)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(92, (3,3), padding='same', activation='relu', trainable=False)(img)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(128, (3,3), padding='same', activation='relu')(img)\n",
    "    \n",
    "    img = Conv2DTranspose(128, (3,3), padding='same', activation='relu')(img)\n",
    "    img = UpSampling2D()(img)\n",
    "    \n",
    "    img = Conv2DTranspose(92, (3,3), padding='same', activation='relu', trainable=False)(img)\n",
    "    img = UpSampling2D()(img)\n",
    "    \n",
    "    img = Conv2DTranspose(64, (3,3), padding='same', activation='relu', trainable=False)(img)\n",
    "    img = UpSampling2D()(img)\n",
    "    \n",
    "    img = Conv2DTranspose(32, (3, 3), padding='same', activation='relu', trainable=False)(img)\n",
    "    img = Conv2DTranspose(32, (3, 3), padding='same', activation='relu', trainable=False)(img)\n",
    "    img = Conv2DTranspose(1, (3, 3), padding='same', activation='sigmoid', trainable=False)(img)\n",
    "\n",
    "    outputs = img\n",
    "\n",
    "    optimizer = RMSprop()\n",
    "    model = Model(inputs=image_input, outputs=outputs)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_v4():\n",
    "    image_input = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "    \n",
    "    img = Conv2D(32, (3, 3), padding='same', activation='relu', trainable=False)(image_input)\n",
    "    img = Conv2D(32, (3, 3), padding='same', activation='relu', trainable=False)(img)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(64, (3,3), padding='same', activation='relu', trainable=False)(img)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(92, (3,3), padding='same', activation='relu')(img)\n",
    "    \n",
    "    img = MaxPooling2D()(img)\n",
    "    img = Conv2D(128, (3,3), padding='same', activation='relu', trainable=False)(img)\n",
    "    \n",
    "    img = Conv2DTranspose(128, (3,3), padding='same', activation='relu', trainable=False)(img)\n",
    "    img = UpSampling2D()(img)\n",
    "    \n",
    "    img = Conv2DTranspose(92, (3,3), padding='same', activation='relu')(img)\n",
    "    img = UpSampling2D()(img)\n",
    "    \n",
    "    img = Conv2DTranspose(64, (3,3), padding='same', activation='relu', trainable=False)(img)\n",
    "    img = UpSampling2D()(img)\n",
    "    \n",
    "    img = Conv2DTranspose(32, (3, 3), padding='same', activation='relu', trainable=False)(img)\n",
    "    img = Conv2DTranspose(32, (3, 3), padding='same', activation='relu', trainable=False)(img)\n",
    "    img = Conv2DTranspose(1, (3, 3), padding='same', activation='sigmoid', trainable=False)(img)\n",
    "\n",
    "    outputs = img\n",
    "\n",
    "    optimizer = RMSprop()\n",
    "    model = Model(inputs=image_input, outputs=outputs)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_model_v4().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "\n",
    "class TensorBoard(Callback):\n",
    "\n",
    "    def __init__(self, log_dir='./logs',\n",
    "                 write_graph=False,\n",
    "                 start_steps=0,\n",
    "                 batch_freq=1):\n",
    "        super(TensorBoard, self).__init__()\n",
    "        \n",
    "        global tf, projector\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.contrib.tensorboard.plugins import projector\n",
    "        \n",
    "        self.log_dir = log_dir\n",
    "        self.batch_freq = batch_freq\n",
    "        self.write_graph = write_graph\n",
    "        \n",
    "        self.start_steps = start_steps\n",
    "        self.steps_counter = 1\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        self.sess = K.get_session()\n",
    "        \n",
    "        self.merged = tf.summary.merge_all()\n",
    "\n",
    "        if self.write_graph:\n",
    "            self.writer = tf.summary.FileWriter(self.log_dir,\n",
    "                                                self.sess.graph)\n",
    "        else:\n",
    "            self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "            \n",
    "    def save_scalar(self, logs):\n",
    "        log = logs or {}\n",
    "        \n",
    "        for name, value in logs.items():\n",
    "            if name in ['batch', 'size']:\n",
    "                continue\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.writer.add_summary(\n",
    "                summary,\n",
    "                self.start_steps + self.steps_counter\n",
    "            )\n",
    "        self.writer.flush()\n",
    "            \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if self.steps_counter % self.batch_freq == 0:\n",
    "            self.save_scalar(logs)\n",
    "        self.steps_counter += 1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.save_scalar(logs)        \n",
    "\n",
    "    def on_train_end(self, _):\n",
    "        self.writer.close()\n",
    "\n",
    "class ModelCheckpoint(Callback):\n",
    "\n",
    "    def __init__(self,\n",
    "                 filepath,\n",
    "                 start_steps=0,\n",
    "                 batch_freq=1):\n",
    "        super(ModelCheckpoint, self).__init__()\n",
    "        \n",
    "        self.filepath = filepath\n",
    "        \n",
    "        self.steps_counter = 0\n",
    "        self.start_steps = start_steps\n",
    "        self.batch_freq = batch_freq\n",
    "        \n",
    "        self.steps_counter\n",
    "        \n",
    "    def save_model(self):\n",
    "        self.model.save_weights(self.filepath, overwrite=True)\n",
    "        \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if self.steps_counter % self.batch_freq == 0:\n",
    "            self.save_model()\n",
    "        self.steps_counter += 1\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_v1 = generate_model_v1()\n",
    "# model_v1.load_weights('./model/model-ae-weight-1.hdf5')\n",
    "# model_v1_weights = model_v1.get_weights()\n",
    "\n",
    "# model_v2 = generate_model_v2()\n",
    "\n",
    "# for i in range(1,3):\n",
    "#     model_v2.layers[i].set_weights(\n",
    "#         model_v1.layers[i].get_weights()\n",
    "#     )\n",
    "    \n",
    "# for i in range(-1,-3,-1):\n",
    "#     model_v2.layers[i].set_weights(\n",
    "#         model_v1.layers[i].get_weights()\n",
    "#     )\n",
    "\n",
    "# del model_v1\n",
    "# model = model_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_v2 = generate_model_v2()\n",
    "# model_v2.load_weights('./model/model-ae-weight-2.hdf5')\n",
    "# model_v2_weights = model_v2.get_weights()\n",
    "\n",
    "# model_v3 = generate_model_v3()\n",
    "\n",
    "# for i in range(1,5):\n",
    "#     print(model_v3.layers[i].name)\n",
    "#     model_v3.layers[i].set_weights(\n",
    "#         model_v2.layers[i].get_weights()\n",
    "#     )\n",
    "    \n",
    "# for i in range(-1,-5,-1):\n",
    "#     print(model_v3.layers[i].name)\n",
    "#     model_v3.layers[i].set_weights(\n",
    "#         model_v2.layers[i].get_weights()\n",
    "#     )\n",
    "\n",
    "# del model_v2\n",
    "# model = model_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v3 = generate_model_v3()\n",
    "model_v3.load_weights('./model/model-ae-weight-3.hdf5')\n",
    "model_v3_weights = model_v3.get_weights()\n",
    "\n",
    "model_v4 = generate_model_v4()\n",
    "\n",
    "for i in range(1,7):\n",
    "    print(model_v3.layers[i].name)\n",
    "    model_v4.layers[i].set_weights(\n",
    "        model_v3.layers[i].get_weights()\n",
    "    )\n",
    "print(\" \")\n",
    "    \n",
    "for i in range(-6,0):\n",
    "    print(model_v3.layers[i].name)\n",
    "    model_v4.layers[i].set_weights(\n",
    "        model_v3.layers[i].get_weights()\n",
    "    )\n",
    "\n",
    "del model_v3\n",
    "model = model_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v4 = generate_model_v4_2()\n",
    "model_v4.load_weights('./model/model-ae-weight-4.hdf5')\n",
    "model = model_v4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    input_generator(x_train_idx),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=input_generator(x_test_idx),\n",
    "    validation_steps=validation_steps,\n",
    "    max_queue_size=3,\n",
    "    epochs=1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=[\n",
    "        TensorBoard(\n",
    "            log_dir=\"./model/logs/\",\n",
    "            batch_freq=5\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=\"./model/model-ae-weight-5.hdf5\",\n",
    "            batch_freq=60\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v4 = generate_model_v4()\n",
    "model_v4.load_weights('./model/model-ae-weight-4.hdf5')\n",
    "model = model_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "for x,y in input_generator(x_test_idx):\n",
    "    print(y[0].reshape(IMAGE_SIZE * IMAGE_SIZE)[0:50])\n",
    "    for i in range(x.shape[0]):\n",
    "        xs = x[i].reshape((IMAGE_SIZE, IMAGE_SIZE))\n",
    "        ys = model.predict(xs.reshape((1, IMAGE_SIZE, IMAGE_SIZE, 1)))\n",
    "        ys = ys[0].reshape((IMAGE_SIZE, IMAGE_SIZE))\n",
    "        \n",
    "        yss = y[i].reshape((IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "#         plt.imshow(xs)\n",
    "#         plt.show()\n",
    "#         plt.imshow(ys)\n",
    "#         plt.show()\n",
    "        \n",
    "        f, axarr = plt.subplots(1,3,figsize=(15,85))\n",
    "        axarr[0].imshow(xs, cmap='Greys')\n",
    "        axarr[1].imshow(yss, cmap='Greys')\n",
    "        axarr[2].imshow(ys, cmap='Greys')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
